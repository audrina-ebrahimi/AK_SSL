{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AK_SSL\n",
    "\n",
    "!pip install AK_SSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from AK_SSL.vision import Trainer\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretext dataset\n",
    "\n",
    "train_unlabeled_dataset = torchvision.datasets.STL10(\n",
    "    root=\"../datasets/\" + \"stl10\",\n",
    "    split=\"unlabeled\",\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define backbone and remove the last layer\n",
    "\n",
    "backbone = torchvision.models.resnet18(weights=None)\n",
    "feature_size = backbone.fc.in_features\n",
    "backbone.fc = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    method=\"barlowtwins\",\n",
    "    backbone=backbone,\n",
    "    feature_size=feature_size,\n",
    "    image_size=96,\n",
    "    save_dir=\"./save_for_report/\",\n",
    "    checkpoint_interval=50,\n",
    "    reload_checkpoint=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "trainer.train(\n",
    "    dataset=train_unlabeled_dataset,\n",
    "    batch_size=256,\n",
    "    start_epoch=1,\n",
    "    epochs=500,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-6,\n",
    "    learning_rate=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluate dataset\n",
    "\n",
    "train_label_dataset = torchvision.datasets.STL10(\n",
    "    root=\"../datasets/\" + \"stl10\",\n",
    "    split=\"train\",\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.STL10(\n",
    "    root=\"../datasets/\" + \"stl10\",\n",
    "    split=\"test\",\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "\n",
    "trainer.evaluate(\n",
    "    train_dataset=train_label_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    eval_method=\"linear\",\n",
    "    top_k=1,\n",
    "    epochs=100,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-6,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=256,\n",
    "    fine_tuning_data_proportion=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Flicker Dataset form kaggle\n",
    "\n",
    "!pip install kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!kaggle datasets download -d adityajn105/flickr8k\n",
    "!unzip flickr8k.zip &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Captions\n",
    "df = pd.read_csv(\"captions.txt\")\n",
    "df.head()\n",
    "\n",
    "# Directory containing the Flickr8k images\n",
    "image_dir = \"Images\"\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# Randomly select 10 image files\n",
    "selected_images = np.random.choice(image_files, size=10, replace=False)\n",
    "\n",
    "# Print the names of the selected images\n",
    "print(\"Selected images:\")\n",
    "for image_file in selected_images:\n",
    "    print(image_file)\n",
    "\n",
    "captions_for_selected_images = []\n",
    "for image_file in selected_images:\n",
    "    caption = np.random.choice(df[df[\"image\"] == image_file][\"caption\"])\n",
    "    captions_for_selected_images.append(caption)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Captions for selected images:\")\n",
    "for caption in captions_for_selected_images:\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert tokenizer from huggingface\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for the Trainer function\n",
    "\n",
    "from AK_SSL.multimodal.models.utils.clip import CustomClipDataset, get_image_transform\n",
    "\n",
    "img_transforms = get_image_transform()\n",
    "\n",
    "dataset = CustomClipDataset(\n",
    "    image_files, captions_for_selected_images, tokenizer, img_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DistilBertModel for text encoder and resnet18 for image encoder\n",
    "\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "\n",
    "txt_encoder = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "img_encoder = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer\n",
    "\n",
    "from AK_SSL.multimodal import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    method=\"CLIP\",\n",
    "    image_encoder=img_encoder,\n",
    "    text_encoder=txt_encoder,\n",
    "    mixed_precision_training=True,\n",
    "    save_dir=\"./save_for_report/\",\n",
    "    checkpoint_interval=50,\n",
    "    reload_checkpoint=False,\n",
    "    verbose=True,\n",
    "    image_feature_dim=0,\n",
    "    text_feature_dim=768,\n",
    "    embed_dim=256,\n",
    "    init_tau=np.log(1.0),\n",
    "    init_bias=0.0,\n",
    "    use_siglip=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "trainer.train(\n",
    "    train_dataset=dataset,\n",
    "    batch_size=256,\n",
    "    start_epoch=1,\n",
    "    epochs=100,\n",
    "    optimizer=\"Adam\",\n",
    "    weight_decay=1e-6,\n",
    "    learning_rate=1e-3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
